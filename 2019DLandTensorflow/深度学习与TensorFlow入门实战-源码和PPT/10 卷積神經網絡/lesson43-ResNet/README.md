# Convolutional Neural Networks, CNN  
## 43 ResNet and DenseNet(æ·±åº¦æ®˜å·®ç¶²è·¯)  


# Introduction of ResNet   

![](resnet.png)   
![](resnet2_net.png)   
- last unit: conv + batchnet + pooling + Relu  
unit here: conv(1,1,64) + relu + conv(3,3,64) + relu + conv(1,1,256) + shortcut  

![](resnet3_shortcut.png)   
- revolution of depth:  
AlexNet, 8 layers (ILSVRC 2012)  
VGG, 19 layers (ILSVRC 2014)  
ResNet, 152 layers (ILSVRC 2015)


- MSRA @ ILSVRC & COCO 2015 competitions  
imageNet classification, detection, localization  
COCO detection, segmentation   
  
- shortcut- why call residual?  
![](resnet4_res.png)


# The comparison of networks   
![](comparison.png)   
- AlexNet - VGG16(20 layers) - GoogleLeNet - ResNet(34, 50, 101, 152)  
VGG16: ä»¥20å±¤ç‚ºåˆ†æ°´å¶º, æ„ˆå¤šå±¤è¡¨ç¾æ„ˆå·®ã€‚ResNetè§£æ±ºäº†é€™å€‹å•é¡Œï¼Œæ„ˆå¤šå±¤æœƒæ„ˆä¾†æ„ˆå¥½ã€‚  
Inception: ç‚ºGoogleNetçš„åŠ æ·±ç‰ˆæœ¬  
- operationé‹ç®—æ€§èƒ½:  
better-ResNet, Inception. ğŸ‘  
worse- VGG(no small window æ²’æœ‰ç”¨å°å·ç©å’ŒæŠ€è¡“, åƒæ•¸è¨ˆç®—é‡å¤§ã€‚)

```py
# Basic block

class BasicBlock(layers.Layer):
    def __int__(self, filter_num, stride=1):
        super(BasicBlock, self).__int__()

        self.conv1 = layers.Conv2D(filter_num, (3,3), strides=stride, padding='same')  
        self.bn1 = layers.BaatchNormalization()
        self.relu = layers.Activation('relu')
        self.conv2 = layers.Conv2D(filter_num, (3,3), strides=1, padding='same')
        self.bn2 = layers.BatchNormalization()
        if stride != 1:
            self.downsample = Sequential()
            self.downsample.add(layers.Conv2D(filter_num, (1,1), strides=stride))
            self.downsample.add(layers.BatchNormalization())
        else:
            self.downsample = lambda x: x
        
        self.stride = stride
    
    def call(self, inputs, training=None):
        residual = self.downsample(inputs)

        conv1 = self.conv1(inputs)
        bn1 = self.bn1(conv1)
        relu1 = self.relu(bn1)
        conv2 = self.conv2(relu1)
        bn2 = self.bn2(conv2)

        add = layers.add([bn2, residual])
        out = self.relu(add)
        return out
        
```
```py
# Res block  
def _build_resblock(self, block, filter_num, blocks, stride=1):
    res_blocks = keras.Sequential()
    res_blocks.add(block(filter_num, stride))

    for _ in range(1, blocks):
        res_blocks.add(block(filter_num, stride=1))

    return res_blocks

```

![](densenet.png)
ä¸­é–“çš„æ¯ä¸€å±¤éƒ½æœ‰å¯èƒ½èˆ‡æœ€é–‹å§‹çš„æ¯ä¸€å±¤æœ‰æ©Ÿæœƒæ¥è§¸ï¼Œé€£æ¥å¾ˆå¯†é›†ã€‚  
å°å‰é¢è¨Šæ¯æœ‰ç¸½å’Œï¼Œä¸æ˜¯elementwiseç›¸åŠ ï¼Œè€Œæ˜¯concateæ“ä½œï¼Œä½¿å¾—å¾Œæ–¹çš„channelè¶Šä¾†è¶Šå¤§ã€‚åä¹‹ï¼Œä½¿ä½ çš„channnelä¸è‡³æ–¼å¤ªå¤§ï¼Œé€™æ˜¯å¾ResNetå»¶ä¼¸è€Œå¾—çš„DenseNetã€‚  





